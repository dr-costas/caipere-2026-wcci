<!DOCTYPE html>
<html lang='en'>
  <head>
    <!--
    Code based on the templates from:
  
    1) https://startbootstrap.com/themes/resume/
    2) https://adminlte.io/themes/AdminLTE/index2.html
  
    -->
    <meta charset='utf-8'>
    <meta name='viewport' content='width=device-width, initial-scale=1, shrink-to-fit=no'>
    <meta name='description' content='Website of the special session on "Computational Audio Intelligence for
  	Perception & Representation (CAIPeRe)", at the IEEE World Congress on Computational Intelligece (WCCI) 2026'>
    <meta name='author' content='K. Drossos'>
  
    <title>CAIPeRe | IEEE WCCI 2026</title>
  
    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="bootstrap/css/bootstrap.min.css">
  
    <!-- Custom fonts for this template -->
    <link href='https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700' rel='stylesheet'>
    <link href='https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i' rel='stylesheet'>
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.1/css/all.css" integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf" crossorigin="anonymous">
  
    <!-- Custom styles for this template -->
    <link href='css/AdminLTE.css' rel='stylesheet'>
    <link href='css/resume.css' rel='stylesheet'>
    <link href="https://unpkg.com/ionicons@4.5.5/dist/css/ionicons.min.css" rel="stylesheet">
  
    <script src="https://unpkg.com/ionicons@4.5.5/dist/ionicons.js"></script>
  
  </head>
  
  <body id='page-top'>
    <nav class='navbar navbar-expand-lg navbar-dark bg-primary fixed-top' id='sideNav'>
      <a class='navbar-brand js-scroll-trigger' href='#page-top'>
  		<span class='d-block d-lg-none'>CAIPeRe</span>
        <span class='d-none d-lg-block'>
  		  CAIPeRe<br>
          WCCI 2026
        </span>
      </a>
      <button class='navbar-toggler' type='button' data-toggle='collapse' data-target='#navbarSupportedContent' aria-controls='navbarSupportedContent' aria-expanded='false' aria-label='Toggle navigation'>
        <span class='navbar-toggler-icon'></span>
      </button>
      <div class='collapse navbar-collapse' id='navbarSupportedContent'>
        <ul class='navbar-nav'>
          <li class='nav-item'>
            <a class='nav-link js-scroll-trigger' href='#about'>About</a>
          </li>
          <li class='nav-item'>
            <a class='nav-link js-scroll-trigger' href='#scopeandtopics'>Scope and topics</a>
          </li>
          <li class='nav-item'>
            <a class='nav-link js-scroll-trigger' href='#organizers'>Organizers</a>
          </li>
          <!-- li class='nav-item'>
            <a class='nav-link js-scroll-trigger' href='#statistics'>Statistics</a>
          </li -->
        </ul>
      </div>
    </nav>
    <!-------------------------------------------------------------------------
    -- About
    -------------------------------------------------------------------------->
    <div class='container-fluid p-0'>
      <section class='resume-section p-3 p-lg-5 d-flex align-items-center' id='about'>
        <div class='w-100'>
          <h1 class='mb-4'>Computational Audio Intelligence for Perception & Representation
            <span class='text-light-blue'>from denoising and spatial hearing to cross-modal understanding</span>
          </h1>
          <div class='subheading mb-5'>
            Special Session at the
            <a href='https://attend.ieee.org/wcci-2026/' target='_blank'>IEEE World Congress on Computational Intelligence (WCCI), 2026</a>
          </div>
          <div class='subheading mb-2'>
            <h3 class='mb-3'>Important dates</h3>
          </div>
          <ul class='fa-ul mb-5'>
            <li>
              <i class='fa-li fa fa-calendar-check'></i>
  		  <h4 class='mb-1'>Paper submission: <span class='text-primary'>31st of January, 2026</span></h4></li>
            <li>
              <i class='fa-li fa fa-calendar-check'></i>
              <h4 class='mb-1'>Notification of Paper Acceptance: <span class='text-primary'>15th of March, 2026</span></h4></li>
            <li>
              <i class='fa-li fa fa-calendar-check'></i>
              <h4 class='mb-1'>Camera-Ready Paper Due: <span class='text-primary'>15th of April, 2026</span></h4></li>
            <li>
              <i class='fa-li fa fa-calendar-check'></i>
              <h4 class='mb-1'>Conference: <span class='text-primary'>22nd - 26th of June, 2026</span></h4></li>
          </ul>
          <br>
          <h3 class='mb-0'><a href="https://attend.ieee.org/wcci-2026/submissions" target='_blank'>Click here to submit your paper!</a></h3>
        </div>
      </section>
      <hr class='m-0'>
      <!-------------------------------------------------------------------------
      -- Scope and topics
      -------------------------------------------------------------------------->
      <section class='resume-section p-3 p-lg-5 d-flex align-items-center' id='scopeandtopics'>
        <div class='w-100'>
          <h2 class='mb-4'>Scope and Topics</h2>
          <div class='resume-item d-flex flex-column flex-md-row justify-content-between mb-5'>
            <div class='resume-content'>
  			<p style="text-align: justify; text-justify: inter-word;">
  			Sound is a <span class="text-primary">fundamental carrier of information</span> for both physical events and human
  			activities. Beyond speech, the auditory domain consists of a multitude of mixtures of environmental, musical,
  			and spatial cues that allow <span class="text-primary">humans and machines to perceive, interpret, and (inter-) act
  			with and within their surroundings</span>. Audio plays an essential role in <span class="text-primary">perceptual
  			intelligence</span>, where the goal is not only to process signals but to <span class="text-primary">learn and infer
  			internal representations that support reasoning and interaction</span>.
  			</p>
  
  			<p style="text-align: justify; text-justify: inter-word;">
  			Recent advances in <span class="text-primary">computational intelligence and machine/deep learning</span> have significantly
  			improved the ability of learning algorithms and computational methods to extract and manipulate meaningful information
  			from audio signals. Methods for <span class="text-primary">denoising, dereverberation, and source separation</span> are
  			increasingly coupled with <span class="text-primary">representation learning methods</span>, enabling the capturing
  			of <span class="text-primary">semantic and spatial aspects of sound</span>. At the same time, data-driven models for
  			<span class="text-primary">spatial hearing, cross-modal learning and correspondence, and generative modeling</span> are
  			reshaping how methods and models represent and synthesize auditory scenes. These developments bridge the traditional
  			boundary between low-level signal enhancement and high-level understanding, showing the way towards a
  			<span class="text-primary">unified perspective on computational audio perception</span>.
  			</p>
  
  			<p style="text-align: justify; text-justify: inter-word;">
  			This special session aims to bring together researchers working across various complementary domains. The goal is to
  			explore how computational intelligence can support robust and adaptive computational audio processing systems, that can
  			generalize across tasks and modalities.
  			</p>
  
              <p>The topics of the special session include (but are not limited to):</p>
              <ul class='fa-ul mb-5'>
                <li>
                  <i class='fa-li fa fa-map-marker-alt'></i>
                  <h5 class='mb-1'><span class="text-primary">Self-supervised learning for audio representation</span></h5>
                </li>
                <li>
                  <i class='fa-li fa fa-map-marker-alt'></i>
                  <h5 class='mb-1'><span class="text-primary">Intelligent denoising, dereverberation, and source separation</span></h5>
                <li>
                  <i class='fa-li fa fa-map-marker-alt'></i>
                <h5 class='mb-1'><span class="text-primary">Spatial audio understanding and neural rendering</span></h5>
                </li>
                <li>
                  <i class='fa-li fa fa-map-marker-alt'></i>
                  <h5 class='mb-1'><span class="text-primary">Cross-modal and multi-sensor fusion for sound perception</span></h5>
                </li>
                <li>
                  <i class='fa-li fa fa-map-marker-alt'></i>
                  <h5 class='mb-1'><span class="text-primary">Generative and diffusion-based models for audio transformation</span></h5>
                </li>
                <li>
                  <i class='fa-li fa fa-map-marker-alt'></i>
                  <h5 class='mb-1'><span class="text-primary">Adaptive, bio-inspired, and neuro-computational models of hearing</span></h5>
                </li>
                <li>
                  <i class='fa-li fa fa-map-marker-alt'></i>
                  <h5 class='mb-1'><span class="text-primary">Applications in machine hearing, AR/VR audio, and auditory scene analysis</span></h5>
                </li>
                <li>
                  <i class='fa-li fa fa-map-marker-alt'></i>
                  <h5 class='mb-1'><span class="text-primary">Context-aware immersive speech processing and applications</span></h5>
                </li>
                <li>
                  <i class='fa-li fa fa-map-marker-alt'></i>
                  <h5 class='mb-1'><span class="text-primary">Audio augmented and mixed reality</span></h5>
                </li>
                <li>
                  <i class='fa-li fa fa-map-marker-alt'></i>
                  <h5 class='mb-1'><span class="text-primary">Machine hearing for 3D audio scene reconstruction</span></h5>
                </li>
                <li>
                  <i class='fa-li fa fa-map-marker-alt'></i>
                  <h5 class='mb-1'><span class="text-primary">Computational hearing aids and assistive listening technologies</span></h5>
                </li>
                <li>
                  <i class='fa-li fa fa-map-marker-alt'></i>
                  <h5 class='mb-1'><span class="text-primary">Audio-based environmental monitoring and smart cities</span></h5>
                </li>
                <li>
                  <i class='fa-li fa fa-map-marker-alt'></i>
                  <h5 class='mb-1'><span class="text-primary">Audio intelligence for autonomous systems and robotics</span></h5>
                </li>
                <li>
                  <i class='fa-li fa fa-map-marker-alt'></i>
                  <h5 class='mb-1'><span class="text-primary">Ethical and social implications of synthetic audio and deepfake</span></h5>
                </li>
                <li>
                  <i class='fa-li fa fa-map-marker-alt'></i>
                  <h5 class='mb-1'><span class="text-primary">Audio-based localization</span></h5>
                </li>
                <li>
                  <i class='fa-li fa fa-map-marker-alt'></i>
                  <h5 class='mb-1'><span class="text-primary">Multimodal audio-visual embeddings for cross-domain perception</span></h5>
                </li>
              </ul>
            </div>
          </div>
        </div>
      </section>
      <hr class='m-0'>
      <!-------------------------------------------------------------------------
      -- Organizing committee
      -------------------------------------------------------------------------->
      <section class='resume-section p-3 p-lg-5 d-flex align-items-center' id='organizers'>
        <div class='w-100'>
          <h2 class='mb-4'>Organizers</h2>
          <ul class='list-inline dev-icons'>
            <li>
              <i class='fa-li fa fa-map-marker-alt'></i>
              <h4 class='mb-1'>
                <span class="text-primary">
                  Emmanouil Benetos</span>,
                Queen Mary University of London, London, U.K.
              </h4>
            </li>
            <li>
              <i class='fa-li fa fa-map-marker-alt'></i>
              <h4 class='mb-1'>
                <span class="text-primary">
                  Konstantinos Drossos</span>,
                Nokia Technologies, Espoo, Finland
              </h4>
            <li>
              <i class='fa-li fa fa-map-marker-alt'></i>
              <h4 class='mb-1'>
                <span class="text-primary">
                  Michele Scarpiniti</span>,
                Sapienza University of Rome, Rome, Italy
              </h4>
            </li>
          </ul>
  		<p>
  		You can <span class="text-primary">contact us</span> for anything about the special session, by
          <ul class='fa-ul mb-5'>
            <li>
              <i class='fa-li fa fa-arrow-right'></i>
              <h4 class='mb-1'>
                <span class="text-primary">
                  creating an issue at the <a href="https://github.com/dr-costas/caipere-2026-wcci", target="_blank">GitHub repository of this website</a> or</span>,
              </h4>
            </li>
            <li>
              <i class='fa-li fa fa-arrow-right'></i>
              <h4 class='mb-1'>
                <span class="text-primary">
                  by <span class="text-primary">sending an email to E. Benetos</span> using firstname [dot] lastname [at] qmul [dot] ac [dot] uk</span>
              </h4>
            <li>
  
  		<!--creating an issue at the <a href="https://github.com/dr-costas/caipere-2026-website", target="_blank">GitHub repository of this website</a>.-->
  		<!--or by <span class="text-primary">sending an email to E. Benetos</span> using firstname [dot] lastname [at] qmul [dot] ac [dot] uk</p>-->
        </div>
      </section>
      <hr class='m-0'>
    </div>
  
    <!-- Bootstrap core JavaScript -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script src="bootstrap/js/bootstrap.min.js"></script>
  
    <!-- Plugin JavaScript -->
    <script src='js/jquery-easing/jquery.easing.min.js'></script>
  
    <!-- Custom scripts for this template -->
    <script src='js/resume.min.js'></script>
    <script src='js/adminlte.js'></script>
  </body>
</html>
