<!DOCTYPE html>
<html lang='en'>
	<head>
    	<!--
    	Code based on the templates from:
    	1) https://startbootstrap.com/themes/resume/
    	2) https://adminlte.io/themes/AdminLTE/index2.html
    	-->
		<meta charset='utf-8'>
    	<meta name='viewport'
		      content='width=device-width,
			           initial-scale=1,
					   shrink-to-fit=no'>
    	<meta name='description'
			  content='Website of the special session on
			  		   "Computational Audio Intelligence for
  					   Perception & Representation (CAIPeRe)",
					   at the IEEE World Congress on Computational
					   Intelligece (WCCI) 2026'>
    	<meta name='author' content='K. Drossos'>
		<!---------------------------------------------------------------------->
    	<title>CAIPeRe | IEEE WCCI 2026</title>
		<!---------------------------------------------------------------------->
    	<!-- Bootstrap core CSS -->
    	<link rel="stylesheet" href="bootstrap/css/bootstrap.min.css">
		<!---------------------------------------------------------------------->
    	<!-- Custom fonts for this template -->
    	<link href='https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700'
			  rel='stylesheet'>
    	<link href='https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i'
			  rel='stylesheet'>
    	<link rel="stylesheet"
			  href="https://use.fontawesome.com/releases/v5.8.1/css/all.css"
			  integrity="sha384-50oBUHEmvpQ+1lW4y57PTFmhCaXp0ML5d60M1M7uH2+nqUivzIebhndOJK28anvf"
			  crossorigin="anonymous">
		<!---------------------------------------------------------------------->
    	<!-- Custom styles for this template -->
    	<link href='css/AdminLTE.css'
			  rel='stylesheet'>
    	<link href='css/resume.css'
			  rel='stylesheet'>
    	<link href="https://unpkg.com/ionicons@4.5.5/dist/css/ionicons.min.css"
			  rel="stylesheet">
		<!---------------------------------------------------------------------->
    	<script src="https://unpkg.com/ionicons@4.5.5/dist/ionicons.js"></script>
	</head>
  	<!-------------------------------------------------------------------------
  	  -------------------------------------------------------------------------
  	  -- Body
  	  -------------------------------------------------------------------------
  	  -------------------------------------------------------------------------->
  	<body id='page-top'>
		<nav class='navbar
				    navbar-expand-lg
				    navbar-dark
				    bg-primary
				    fixed-top'
		     id='sideNav'>
			<a class='navbar-brand
		  		      js-scroll-trigger'
		       href='#page-top'>
			  <span class='d-block d-lg-none'>
				  CAIPeRe
			  </span>
			  <span class='d-none d-lg-block'>
				  CAIPeRe<br>
				  WCCI 2026
			  </span>
			</a>
			<button class='navbar-toggler'
		  	        type='button'
			        data-toggle='collapse'
			        data-target='#navbarSupportedContent'
			        aria-controls='navbarSupportedContent'
			        aria-expanded='false'
			        aria-label='Toggle navigation'>
				<span class='navbar-toggler-icon'></span>
			</button>
			<div class='collapse
				        navbar-collapse'
			     id='navbarSupportedContent'>
				<ul class='navbar-nav'>
					<li class='nav-item'>
						<a class='nav-link
						   		  js-scroll-trigger'
			   		       href='#about'>
							About
						</a>
					</li>
					<li class='nav-item'>
						<a class='nav-link
					   		  	  js-scroll-trigger'
					       href='#scopeandtopics'>
							Scope and topics
						</a>
					</li>
					<li class='nav-item'>
						<a class='nav-link
					  		  	  js-scroll-trigger'
					   	   href='#organizers'>
							Organizers
						</a>
					</li>
				</ul>
			</div>
		</nav>
    	<div class='container-fluid p-0'>
    		<!-------------------------------------------------------------------
    		-- About
    		-------------------------------------------------------------------->
			<section class='resume-section
		  			  		p-3
					  		p-lg-5
					  		d-flex
					  		align-items-center'
			         id='about'>
				<div class='w-100'>
					<h1 class='mb-4'>
						Computational Audio Intelligence for Perception &
						Representation
						<span class='text-light-blue'>
							from denoising and spatial hearing to cross-modal
							understanding
						</span>
					</h1>
					<div class='subheading mb-5'>
						Special Session at the
						<a href='https://attend.ieee.org/wcci-2026/'
						   target='_blank'>
							IEEE World Congress on Computational Intelligence (WCCI),
							2026
						</a>
					</div>
					<div class='subheading mb-2'>
						<h3 class='mb-3'>
							Important dates
						</h3>
					</div>
					<ul class='fa-ul mb-5'>
						<li>
							<i class='fa-li fa fa-calendar-check'></i>
							<h4 class='mb-1'>
								Paper submission:
								 <span class='text-muted'><del>
								<!-- <span class='text-primary'> -->
									31st of January, 2026
								</del></span> 
								<!-- </span> -->
							</h4>
						</li>
						<li>
							<i class='fa-li fa fa-calendar-check'></i>
							<h4 class='mb-1'>
								Notification of Paper Acceptance:
								<span class='text-primary'>
									15th of March, 2026
								</span>
							</h4>
						</li>
						<li>
							<i class='fa-li fa fa-calendar-check'></i>
							<h4 class='mb-1'>
								Camera-Ready Paper Due:
								<span class='text-primary'>
									15th of April, 2026
								</span>
							</h4>
						</li>
						<li>
							<i class='fa-li fa fa-calendar-check'></i>
							<h4 class='mb-1'>
								Conference:
								<span class='text-primary'>
									22nd - 26th of June, 2026
								</span>
							</h4>
						</li>
					</ul>
					<br>
					<h3 class='mb-0'>
						<a href="https://attend.ieee.org/wcci-2026/submissions"
							target='_blank'>Click here to submit your paper!
						</a>
					</h3>
				</div>
			</section>
			<hr class='m-0'>
	  		<!-------------------------------------------------------------------
      		-- Scope and topics
      		-------------------------------------------------------------------->
			<section class='resume-section
						    p-3
							p-lg-5
							d-flex
							align-items-center'
					 id='scopeandtopics'>
				<div class='w-100'>
					<h2 class='mb-4'>
						Scope and Topics
					</h2>
					<div class='resume-item
								d-flex
								flex-column
								flex-md-row
								justify-content-between
								mb-5'>
						<div class='resume-content'>
							<p style="text-align: justify;
									  text-justify: inter-word;">
								Sound is a <span class="text-primary">fundamental
								carrier of information</span> for both physical
								events and human activities. Beyond speech, the
								auditory domain consists of a multitude of mixtures
								of environmental, musical, and spatial cues that
								allow <span class="text-primary">humans and machines
								to perceive, interpret, and (inter-) act with and
								within their surroundings</span>. Audio plays an
								essential role in <span class="text-primary">perceptual
								intelligence</span>, where the goal is not only to
								process signals but to <span class="text-primary">
								learn and infer internal representations that support
								reasoning and interaction</span>.
							</p>
	  						<!----------------------------------------------------->
  							<p style="text-align: justify; text-justify: inter-word;">
  								Recent advances in <span class="text-primary">computational
								intelligence and machine/deep learning</span> have
								significantly improved the ability of learning algorithms
								and computational methods to extract and manipulate
								meaningful information from audio signals. Methods for
								<span class="text-primary">denoising, dereverberation,
								and source separation</span> are increasingly coupled
								with <span class="text-primary">representation learning
								methods</span>, enabling the capturing of <span
								class="text-primary">semantic and spatial aspects of
								sound</span>. At the same time, data-driven models for
								<span class="text-primary"> spatial hearing, cross-modal
								learning and correspondence, and generative modeling</span>
								are reshaping how methods and models represent and
								synthesize auditory scenes. These developments bridge
								the traditional boundary between low-level signal
								enhancement and high-level understanding, showing the
								way towards a <span class="text-primary">unified
								perspective on computational audio perception</span>.
  							</p>
	  						<!------------------------------------------------------->
  							<p style="text-align: justify; text-justify: inter-word;">
  								This special session aims to bring together researchers
								working across various complementary domains. The goal
								is to explore how computational intelligence can support
								robust and adaptive computational audio processing systems,
								that can generalize across tasks and modalities.
  							</p>
	  						<!------------------------------------------------------->
              				<p>
								The topics of the special session include (but are not
							  	limited to):
							</p>
							<ul class='fa-ul mb-5'>
								<li>
									<i class='fa-li fa fa-map-marker-alt'></i>
									<h5 class='mb-1'>
										<span class="text-primary">
											Self-supervised learning for audio representation
										</span>
									</h5>
								</li>
								<li>
									<i class='fa-li fa fa-map-marker-alt'></i>
									<h5 class='mb-1'>
										<span class="text-primary">
											Intelligent denoising, dereverberation, and
											source separation
										</span>
									</h5>
								<li>
									<i class='fa-li fa fa-map-marker-alt'></i>
									<h5 class='mb-1'>
										<span class="text-primary">
											Spatial audio understanding and neural rendering
										</span>
									</h5>
								</li>
								<li>
									<i class='fa-li fa fa-map-marker-alt'></i>
									<h5 class='mb-1'>
										<span class="text-primary">
											Cross-modal and multi-sensor fusion for
											sound perception
										</span>
									</h5>
								</li>
								<li>
									<i class='fa-li fa fa-map-marker-alt'></i>
									<h5 class='mb-1'>
										<span class="text-primary">
											Generative and diffusion-based models for audio
											transformation
										</span>
									</h5>
								</li>
								<li>
									<i class='fa-li fa fa-map-marker-alt'></i>
									<h5 class='mb-1'>
										<span class="text-primary">
											Adaptive, bio-inspired, and neuro-computational
											models of hearing
										</span>
									</h5>
								</li>
								<li>
									<i class='fa-li fa fa-map-marker-alt'></i>
									<h5 class='mb-1'>
										<span class="text-primary">
											Applications in machine hearing, AR/VR audio,
											and auditory scene analysis
										</span>
									</h5>
								</li>
								<li>
									<i class='fa-li fa fa-map-marker-alt'></i>
									<h5 class='mb-1'>
										<span class="text-primary">
											Context-aware immersive speech processing and
											applications
										</span>
									</h5>
								</li>
								<li>
									<i class='fa-li fa fa-map-marker-alt'></i>
									<h5 class='mb-1'>
										<span class="text-primary">
											Audio augmented and mixed reality
										</span>
									</h5>
								</li>
								<li>
									<i class='fa-li fa fa-map-marker-alt'></i>
									<h5 class='mb-1'>
										<span class="text-primary">
											Machine hearing for 3D audio scene reconstruction
										</span>
									</h5>
								</li>
								<li>
									<i class='fa-li fa fa-map-marker-alt'></i>
									<h5 class='mb-1'>
										<span class="text-primary">
											Computational hearing aids and assistive
											listening technologies
										</span>
									</h5>
								</li>
								<li>
									<i class='fa-li fa fa-map-marker-alt'></i>
									<h5 class='mb-1'>
										<span class="text-primary">
											Audio-based environmental monitoring and smart
											cities
										</span>
									</h5>
								</li>
								<li>
									<i class='fa-li fa fa-map-marker-alt'></i>
									<h5 class='mb-1'>
										<span class="text-primary">
											Audio intelligence for autonomous systems and
											robotics
										</span>
									</h5>
								</li>
								<li>
									<i class='fa-li fa fa-map-marker-alt'></i>
									<h5 class='mb-1'>
										<span class="text-primary">
											Ethical and social implications of synthetic
											audio and deepfake
										</span>
									</h5>
								</li>
								<li>
									<i class='fa-li fa fa-map-marker-alt'></i>
									<h5 class='mb-1'>
										<span class="text-primary">
											Audio-based localization
										</span>
									</h5>
								</li>
								<li>
									<i class='fa-li fa fa-map-marker-alt'></i>
									<h5 class='mb-1'>
										<span class="text-primary">
											Multimodal audio-visual embeddings for
											cross-domain perception
										</span>
									</h5>
								</li>
							</ul>
						</div>
					</div>
				</div>
			</section>
			<hr class='m-0'>
      		<!-------------------------------------------------------------------
      		-- Organizing committee
      		-------------------------------------------------------------------->
      		<section class='resume-section
							p-3
							p-lg-5
							d-flex
							align-items-center'
					 id='organizers'>
				<div class='w-100'>
					<h2 class='mb-4'>
						Organizers
					</h2>
					<ul class='list-inline dev-icons'>
						<li>
							<i class='fa-li fa fa-map-marker-alt'></i>
							<h4 class='mb-1'>
								<span class="text-primary">
									Emmanouil Benetos
								</span>-
								Queen Mary University of London, London, U.K.
							</h4>
						</li>
						<li>
							<i class='fa-li fa fa-map-marker-alt'></i>
							<h4 class='mb-1'>
								<span class="text-primary">
									Konstantinos Drossos
								</span>-
								Nokia Technologies, Espoo, Finland
							</h4>
						</li>
						<li>
							<i class='fa-li fa fa-map-marker-alt'></i>
							<h4 class='mb-1'>
								<span class="text-primary">
									Michele Scarpiniti
								</span>-
								Sapienza University of Rome, Rome, Italy
							</h4>
						</li>
					</ul>
					<p>
						You can <span class="text-primary">contact us</span>
						for anything about the special session, by
					</p>
					<ul class='fa-ul mb-5'>
						<li>
							<i class='fa-li fa fa-arrow-right'></i>
							<h4 class='mb-1'>
								<span class="text-primary">
									creating an issue at the
									<a href="https://github.com/dr-costas/caipere-2026-wcci",
									   target="_blank">
										GitHub repository of this website
									</a> or
								</span>,
							</h4>
						</li>
						<li>
							<i class='fa-li fa fa-arrow-right'></i>
							<h4 class='mb-1'>
								<span class="text-primary">
									by
									<span class="text-primary">
										sending an email to E. Benetos
									</span>
									using firstname [dot] lastname [at] qmul
									[dot] ac [dot] uk
								</span>
							</h4>
						</li>
					</ul>
				</div>
			</section>
		</div>
		<!---------------------------------------------------------------------->
    	<!-- Bootstrap core JavaScript -->
    	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    	<script src="bootstrap/js/bootstrap.min.js"></script>
		<!---------------------------------------------------------------------->
    	<!-- Plugin JavaScript -->
    	<script src='js/jquery-easing/jquery.easing.min.js'></script>
		<!---------------------------------------------------------------------->
    	<!-- Custom scripts for this template -->
    	<script src='js/resume.min.js'></script>
    	<script src='js/adminlte.js'></script>
		<!---------------------------------------------------------------------->
  	</body>
</html>
